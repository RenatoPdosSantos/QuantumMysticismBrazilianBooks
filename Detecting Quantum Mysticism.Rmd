---
title: "Detecting Quantum Mysticism in Books Published in Brazil with Data Science"
author: "Renato P. dos Santos"
date: "12 July 2017"
output: word_document
---

```{r WScleaning, echo = FALSE}
# Clean up workspace
rm(list=ls())
```

```{r environment, echo = FALSE}
# Environment Details
R.version <- sessionInfo()$R.version$version.string
RStudio.version <- RStudio.Version()$version
OS.version <- sessionInfo()$running
platform <- sessionInfo()$platform
```

```{r packages, echo = FALSE}
# Install packages
suppressMessages(library(stringi)) # Character string processing facilities 
suppressMessages(library(ggplot2)) # Elegant data visualisations using the grammar of graphics
suppressMessages(library(Cairo)) # Cairo graphics library for  high-quality output
suppressMessages(library(stringr)) # Simple wrappers for common string operations 
suppressMessages(library(plyr)) # Tools for Splitting, Applying and Combining Data. Required for XGBoost Method (must be loaded before dplyr)
suppressMessages(library(dplyr)) # A grammar of data manipulation
suppressMessages(library(cowplot)) # Streamlined plot theme and plot annotations for 'ggplot2'
suppressMessages(library(tm)) # Text mining
suppressMessages(library(tidytext)) # Text mining using 'dplyr', 'ggplot2', and other tidy tools
suppressMessages(library(xlsx)) # Read, write, and format Excel files
suppressMessages(library(caret)) # Integrated interface for training, plotting, classification and regression models.
suppressMessages(library(kernlab)) # SVM method
suppressMessages(library(xgboost)) ## XGBoost method
suppressMessages(library(randomForest)) # Random Forest method
suppressMessages(library(e1071)) # Various machine learning methods
suppressMessages(library(rpart)) # RPART method 
suppressMessages(library(rpart.plot)) # Extends plotting and text facilities in the 'rpart' package.
suppressMessages(library(rattle)) # Graphical user interface for data mining in R
suppressMessages(library(knitr)) # general-purpose tool for dynamic report generation in R
```

## Abstract

Brazilian bookstores have been flooded with titles including the word 'quantum,' but more of 'quantum mysticism' flavour, which purports the existence of links between quantum mechanics and Eastern mysticism, leading to serious misunderstandings. This work aims to identify terms that can help readers, especially high-school teachers, to recognize to which of those categories a book pertains even before reading it through, contributing to breaking the vicious circle of students learning pseudoscience and passing it on as truth. 22 terms were identified that discriminate with an accuracy of 94% between the categories 'quantum mysticism' and science or science popularization. 

## Data

The online catalogs of the four largest bookstores in Brazil, Cultura, Saraiva, Amazon and FNAC, were searched in two moments: the first, between March and April 2016, and the second in October 2016. To avoid subjectivity in the selection of Books, objective criteria were defined: in the initial collection of the books, only books containing the words 'quantum' or 'quantum' in their titles were selected; In the second, not only books with the words 'quantum' or 'quantum' were selected in their titles that, for some reason, escaped the first collection, but also books that, even without containing those words in the title, contained them in the synopsis.

For each book, a record was created containing additional data, such as author's name, synopsis, and publication date. However, only the titles and synopses of the books constituted the corpus of the text analysis.
This database was analyzed using data science techniques, specifically using the text mining, text analysis, and machine learning from R language (R Core Team, 2016) `r R.version`. Although R is very versatile and has lots of features, all the work was done in a reasonable time on a conventional desktop, with `r platform` architecture, and `r OS.version`.

```{r reading, echo = FALSE}
# Read the data from the .xlsx file.
booksData <- read.xlsx(
    "data/books.xlsx",
    sheetIndex = 1,
    as.data.frame=TRUE,
    header = TRUE,
    stringsAsFactors = FALSE,
    encoding = "UTF-8"
)

booksData$Disponibilidade <- as.factor(booksData$Disponibilidade)
booksData$Genero <- as.factor(booksData$Genero)
booksData$Categoria <- as.factor(booksData$Categoria)
booksData$Origem <- as.factor(booksData$Origem)
booksData$Nacionalidade <- as.factor(booksData$Nacionalidade)
booksData$Idioma <- as.factor(booksData$Idioma)

# Unavailable data are encoded as NA
booksData$Sinopse[booksData$Sinopse == "N/A"] <- NA
```

The database contains `r nrow(booksData)` rows (books) and 15 columns (book data).

The 15 variables in the database are:
 1 N
 2 Titulo
 3 Autor
 4 Editora
 5 Ano
 6 Disponibilidade
 7 Preco
 8 Genero
 9 Categoria
10 Link
11 Paginas
12 Origem
13 Nacionalidade
14 Idioma
15 Sinopse

## Analysis

The books were originally classified by bookstores in various, and sometimes arbitrary, genres such as 'Self-Help', 'Exact Sciences - Physics', 'Alternative Medicine', or even 'Infantile', as can be seen from the legend in Figure 1. This classification may merit a study by itself, but it would transcend the scope of this work. 

```{r Summary}
SummTitulo <- lapply(booksData$Titulo, stri_stats_latex)
kable(summary(t(as.data.frame(SummTitulo))))
SummSinopse <- lapply(booksData$Sinopse, stri_stats_latex)
kable(summary(t(as.data.frame(SummSinopse))))
```


```{r by Genre}
# Histogram by Genre and year of publication
plot2 <- ggplot(data = booksData, aes(x = Ano))
plot2 <- plot2 + geom_histogram(binwidth = 1, 
                                aes(fill = Genero),
                                na.rm = TRUE)
plot2 <- plot2 + theme(text = element_text(size = 24),
                       axis.text = element_text(size = 24),
                       legend.text = element_text(size = 20))
plot2 <- plot2 + guides(fill = guide_legend(ncol = 1))
plot2 <- plot2 + ylab("Livros")
plot2 <- plot2 + xlab("Ano")
plot2
```

For the purposes of this work, the books were reclassified into only three categories, according to Bunge's (1982) 'demarcation criteria: 'science' (including technology), 'pseudoscience' and 'non-science' (including knowledge fields that are not based on science without, however, coming into conflict with it, such as literature). We did not see the need to include the fourth category proposed by Bunge (1982), 'proto-science', which includes fields of knowledge in the process of becoming scientific. The totals of books in each category are presented in Table 1. 

```{r recategorize}
# Recategoriza os livros em 3 categorias gerais: Science, Pseudoscience & Non-Science
categorization <- matrix(
    data = c(
        c("Administracao", "ciência"),
        c("Autoajuda", "pseudociência"),
        c("Ciencias Biologicas", "ciência"),
        c("Direito", "ciência"),
        c("Engenharia", "ciência"),
        c("Esoterismo", "pseudociência"),
        c("Filosofia", "ciência"),
        c("Fisica", "ciência"),
        c("Historia", "ciência"),
        c("Informatica", "ciência"),
        c("Literatura", "não-ciência"),
        c("Medicina", "ciência"),
        c("Medicina Alternativa", "pseudociência"),
        c("Pedagogia", "ciência"),
        c("Psicologia", "ciência"),
        c("Quimica", "ciência"),
        c("Religiao", "não-ciência")
    ),
    nrow = 17,
    ncol = 2,
    byrow = TRUE
)

booksData$GenCat <- as.factor(categorization[match(booksData$Categoria,
                                                categorization[, 1]), 2])
```

```{r Table1, echo = FALSE}
GenCatTable <-
        data.frame(table(booksData$GenCat), stringsAsFactors = FALSE)

colnames(GenCatTable) <- c('GenCat', 'Freq')

GenCatTable <-
        GenCatTable[order(GenCatTable$Freq, decreasing = TRUE),]

row.names(GenCatTable) <- NULL
GenCatTable$GenCat <- as.character(GenCatTable$GenCat)

GenCatTable <-
        rbind(GenCatTable, c('Totals', sum(GenCatTable$Freq)))
GenCatTable$Freq <- as.integer(GenCatTable$Freq)
GenCatTable$'%' <- 100 * GenCatTable$Freq / GenCatTable$Freq[nrow(GenCatTable)]

kable(GenCatTable, 
      digits = 0, 
      caption = 'Tabela 1 – Distribuição dos livros segundo as categorias.')
```

As a first result of this exploratory analysis, it was verified that the current availability of scientific books dates back to the 1970s, while a growing trend of pseudoscientific works has emerged in Brazil since 2000 (Figure 2).

```{r by Category}
# Histogram by Category and year of publication, separated by GenCat
ylims <- c(0, 15)
sc <-
    ggplot(data = subset(booksData,
                         GenCat == "ciência"),
           aes(x = Ano))
sc <- sc + geom_histogram(binwidth = 1,
                          aes(fill = Categoria),
                          na.rm = TRUE)
sc <- sc + ylim(ylims)
sc <- sc + theme(
    plot.title = element_text(size = 20,
                              face = "bold"),
    text = element_text(size = 20),
    axis.text = element_text(size = 20),
    legend.text = element_text(size = 20)
)
sc <- sc + ylab("Livros")
sc <- sc + xlab("Ano")
sc <- sc + ggtitle("Ciência")

pc <-
    ggplot(data = subset(booksData,
                         GenCat == "pseudociência"),
           aes(x = Ano))
pc <- pc + geom_histogram(binwidth = 1,
                          aes(fill = Categoria),
                          na.rm = TRUE)
pc <- pc + ylim(ylims)
pc <- pc + theme(
    plot.title = element_text(size = 20,
                              face = "bold"),
    text = element_text(size = 20),
    axis.text = element_text(size = 20),
    legend.text = element_text(size = 20)
)
pc <- pc + ylab("Livros")
pc <- pc + xlab("Ano")
pc <- pc + ggtitle("Pseudociência")

nc <-
    ggplot(data = subset(booksData, GenCat == "não-ciência"), aes(x = Ano))
nc <- nc + geom_histogram(binwidth = 1,
                          aes(fill = Categoria),
                          na.rm = TRUE)
nc <- nc + ylim(ylims)
nc <- nc + theme(
    plot.title = element_text(size = 20,
                              face = "bold"),
    text = element_text(size = 20),
    axis.text = element_text(size = 20),
    legend.text = element_text(size = 20)
)
nc <- nc + ylab("Livros")
nc <- nc + xlab("Ano")
nc <- nc + ggtitle("Não-ciência")

plot_grid(sc,
          pc,
          nc,
          ncol = 1,
          nrow = 3,
          align = "v")
```

The 'non-science' category was abandoned because it had little presence in the set of books listed and, mainly, because it does not cause prejudice to the learning in science, since it included only works of literature, such as the science-fiction book 'Quantum Utopy' and 'The mystery of the black sphere and the Quantum box'.  

```{r nonscience, echo = FALSE}
booksData <- booksData[booksData$GenCat != 'não-ciência', ]
booksData$GenCat <- as.factor(as.character(booksData$GenCat))
```

This choice reduced the data set to `r nrow(booksData[booksData$Idioma == "Portugues" & (booksData$GenCat == "ciência" | booksData$GenCat == "pseudociência"),])` books.

From the `r nrow(booksData)` collected books, we selected only those written in Portuguese for the analysis of text, reducing the database to `r nrow(booksData[booksData$Idioma == "Portugues", ])`.

Using the text mining tm package of the language R (Feinerer; Hornik; Meyer, 2008), the titles and synopses of these books were then transformed into unnoted linguistic corpora for further processing.  

```{r corpora}
# Convert titles and synopses into corpora
titlesCorpus <- data.frame(DocNo = booksData$N,
                           Title = booksData$Titulo,
                           GenCat = booksData$GenCat,
                           Idiom = booksData$Idioma,
                           stringsAsFactors = FALSE)
titlesCorpus <- subset(titlesCorpus, Idiom == "Portugues")
titlesCorpus$Idiom <- NULL

synopsesCorpus <- data.frame(DocNo = booksData$N,
                           Synopsis = booksData$Sinopse,
                           GenCat = booksData$GenCat,
                           Idiom = booksData$Idioma,
                           stringsAsFactors = FALSE)
synopsesCorpus <- subset(synopsesCorpus, Idiom == "Portugues")
synopsesCorpus$Idiom <- NULL
```

The words of the corpora were transformed into lower case letters, punctuation marks and other special characters, excess spaces and numbers. Empty words (*stop words*) were also removed using empty package lists from *package tm*, from [Snowball project][1] and from [ranks.nl][2].

[1]: http://snowball.tartarus.org/algorithms/portuguese/stop.txt
[2]: http://www.ranks.nl/stopwords/brazilian

```{r Scleaning}
# Cleaning dataset
titlesCorpus <- na.exclude(titlesCorpus)
synopsesCorpus <- na.exclude(synopsesCorpus)

# Transform words to lower case
titlesCorpus$Title <- tolower(titlesCorpus$Title)
synopsesCorpus$Synopsis <- tolower(synopsesCorpus$Synopsis)

# Remove punctuation and other special characters
titlesCorpus$Title <- removePunctuation(titlesCorpus$Title,
                                        preserve_intra_word_dashes = TRUE)
synopsesCorpus$Synopsis <- removePunctuation(synopsesCorpus$Synopsis,
                                        preserve_intra_word_dashes = TRUE)

# Transliterate accented characters by their counterparts without accents
titlesCorpus$Title <- iconv(titlesCorpus$Title, from = "UTF-8", to = "ASCII//TRANSLIT", sub = "")
synopsesCorpus$Synopsis <- iconv(synopsesCorpus$Synopsis, from = "UTF-8", to = "ASCII//TRANSLIT", sub = "")

# Replace numbers with the string 'NUMBER'
replaceNumbers <- function(x)
        gsub("[0-9]+", "NUMBER", x)
titlesCorpus$Title <- replaceNumbers(titlesCorpus$Title)
synopsesCorpus$Synopsis <- replaceNumbers(synopsesCorpus$Synopsis)

# Replace dollar signs ($) with the string 'DOLLAR'
replaceDollarSigns <- function(x)
    gsub("[$]+", "DOLLAR", x)
titlesCorpus$Title <- replaceDollarSigns(titlesCorpus$Title)
synopsesCorpus$Synopsis <- replaceDollarSigns(synopsesCorpus$Synopsis)

# Replace percent signs (%) with the string 'PERCENT'
replacePercentSigns <- function(x)
    gsub("[%]+", "PERCENT", x)
titlesCorpus$Title <- replacePercentSigns(titlesCorpus$Title)
synopsesCorpus$Synopsis <- replacePercentSigns(synopsesCorpus$Synopsis)

# Remove words beginning with hyphens
removeInHyphen <- function(x)
    gsub("-[A-Za-z]+ ", "", x)
titlesCorpus$Title <- removeInHyphen(titlesCorpus$Title)
synopsesCorpus$Synopsis <- removeInHyphen(synopsesCorpus$Synopsis)

# Remove words ending with hyphens
removeFinHyphen <- function(x)
    gsub("[A-Za-z]+- ", "", x)
titlesCorpus$Title <- removeFinHyphen(titlesCorpus$Title)
synopsesCorpus$Synopsis <- removeFinHyphen(synopsesCorpus$Synopsis)

# Remove hyphens
removeMidHyphen <- function(x)
    gsub(" - ", " ", x)
titlesCorpus$Title <- removeMidHyphen(titlesCorpus$Title)
synopsesCorpus$Synopsis <- removeMidHyphen(synopsesCorpus$Synopsis)

# Remove words with less than 3 letters
# removeLessThanThree <- function(x)
#     gsub("\\b\\w{1,3}\\b ", " ",x)
# titlesCorpus$Title <- removeLessThanThree(titlesCorpus$Title)
# synopsesCorpus$Synopsis <- removeLessThanThree(synopsesCorpus$Synopsis)

# Remove trivial words for graphing
trivialwords <- c("quantica", "quantico")
titlesCorpus$Title <- removeWords(titlesCorpus$Title,
                                  trivialwords)
synopsesCorpus$Synopsis <- removeWords(synopsesCorpus$Synopsis,
                                  trivialwords)

# Remove Portuguese stopwords
titlesCorpus$Title <- removeWords(titlesCorpus$Title,
                                  stopwords('portuguese'))
synopsesCorpus$Synopsis <- removeWords(synopsesCorpus$Synopsis,
                                  stopwords('portuguese'))

# Remove more Portuguese stopwords
morestopwords <- readLines("data/stopwords.txt") 
titlesCorpus$Title <- removeWords(titlesCorpus$Title,
                                  morestopwords)
synopsesCorpus$Synopsis <- removeWords(synopsesCorpus$Synopsis,
                                  morestopwords)

# Remove other special characters
removeSpecialChars <- function(x)
        gsub("[^-a-z?-?0-9$ ]", "", x)
titlesCorpus$Title <- removeSpecialChars(titlesCorpus$Title)
synopsesCorpus$Synopsis <- removeSpecialChars(synopsesCorpus$Synopsis)

# Strip out extra whitespace 
titlesCorpus$Title <- str_trim(stripWhitespace(titlesCorpus$Title), 
                  side = 'both')
synopsesCorpus$Synopsis <- str_trim(stripWhitespace(synopsesCorpus$Synopsis), 
                  side = 'both')
```

```{r frequencies, echo = FALSE}
# Dataset containing the relative frequencies of each word in each document plus the categories associated to the document and the original document number
titlesCorpus$NWords <- str_count(titlesCorpus$Title, "[[:alpha:]]+")
titlesWords <-
        unnest_tokens(
                titlesCorpus,
                Words,
                Title,
                token = 'words',
                drop = TRUE
        )
titlesWords$Freq <- 0
titlesWords <- aggregate(Freq ~ Words + DocNo + GenCat + NWords,
                         data = titlesWords,
                         FUN = length)
titlesWords <- mutate(titlesWords, Freq = Freq / NWords)
titlesWords$NWords <- NULL
titlesWords <-
        titlesWords[order(titlesWords$Freq, decreasing = TRUE), ]

synopsesCorpus$NWords <- str_count(synopsesCorpus$Synopsis, "[[:alpha:]]+")
synopsesWords <-
        unnest_tokens(
                synopsesCorpus,
                Words,
                Synopsis,
                token = 'words',
                drop = TRUE
        )
synopsesWords$Freq <- 0
synopsesWords <- aggregate(Freq ~ Words + DocNo + GenCat + NWords,
                         data = synopsesWords,
                         FUN = length)
synopsesWords <- mutate(synopsesWords, Freq = Freq / NWords)
synopsesWords$NWords <- NULL
synopsesWords <-
        synopsesWords[order(synopsesWords$Freq, decreasing = TRUE), ]
```

Instead of constructing indexes (*document-term matrices*), from the corpora, databases were produced in which the words consisted of columns and their relative frequencies in each book in the lines.

Since the syntax of the R language does not allow for accented or special characters, such as hyphen, in the name of the variables, the words of the titles and the synopses had to be transliterated to their correspondents without accent and to a point, instead of the hyphen.

To ensure the best discrimination between the 'science' and 'pseudoscience' categories, words associated with both categories simultaneously were discarded.

```{r synopsesData}
# The words of the synopses had to be standardized to be variable names 
titlesWords$Words <- make.names(titlesWords$Words, unique = FALSE, allow_ = FALSE)
synopsesWords$Words <- make.names(synopsesWords$Words, unique = FALSE, allow_ = FALSE)

# Select words associated with only one of the categories 
scienceWords <-
        titlesWords$Words[titlesWords$GenCat == 'ciência']
pseudoscienceWords <-
        titlesWords$Words[titlesWords$GenCat == 'pseudociência']
titlesDataColNames <-
        unique(setdiff(pseudoscienceWords, scienceWords))

# Build datasets
titlesData <- titlesCorpus[, c('DocNo', 'GenCat')]
for (i in 1:length(titlesDataColNames)) {
        Var = as.character(titlesDataColNames[i])
        titlesData <-
                data.frame(titlesData,
                           Var = titlesData$DocNo %in% titlesWords$DocNo[titlesWords$Words == titlesDataColNames[i]])
        titlesData <-
                plyr::rename(titlesData, c('Var' = Var))
}

titlesData <- titlesCorpus[, c('DocNo', 'GenCat')]
for (i in 1:length(titlesDataColNames)) {
        Var = as.character(titlesDataColNames[i])
        titlesData <-
                data.frame(
                        titlesData,
                        Var = ifelse(
                                titlesData$DocNo %in% titlesWords$DocNo[titlesWords$Words == titlesDataColNames[i]],
                                titlesWords$Freq[titlesWords$Words == titlesDataColNames[i]],
                                0
                        )
                )
        titlesData <-
                plyr::rename(titlesData, c('Var' = Var))
}

scienceWords <-
        synopsesWords$Words[synopsesWords$GenCat == 'ciência']
pseudoscienceWords <-
        synopsesWords$Words[synopsesWords$GenCat == 'pseudociência']
synopsesDataColNames <-
        unique(setdiff(pseudoscienceWords, scienceWords))

synopsesData <- synopsesCorpus[, c('DocNo', 'GenCat')]
for (i in 1:length(synopsesDataColNames)) {
        Var = as.character(synopsesDataColNames[i])
        synopsesData <-
                data.frame(synopsesData,
                           Var = synopsesData$DocNo %in% synopsesWords$DocNo[synopsesWords$Words == synopsesDataColNames[i]])
        synopsesData <- plyr::rename(synopsesData, c('Var' = Var))
}

synopsesData <- synopsesCorpus[, c('DocNo', 'GenCat')]
for (i in 1:length(synopsesDataColNames)) {
        Var = as.character(synopsesDataColNames[i])
        synopsesData <-
                data.frame(
                        synopsesData,
                        Var = ifelse(
                                synopsesData$DocNo %in% synopsesWords$DocNo[synopsesWords$Words == synopsesDataColNames[i]],
                                synopsesWords$Freq[synopsesWords$Words == synopsesDataColNames[i]],
                                0
                        )
                )
        synopsesData <- plyr::rename(synopsesData, c('Var' = Var))
}
```

Due to the small extension of the base, and because the synopses and, even more, the titles of the books, consisted of short texts, the remaining words were sparse, that is to say, with little frequency in the texts, making analysis extremely difficult by usual methods, such as the *bag of words* (Harris, 1954).

Although words with almost constant frequencies in all texts of the corpus, also called predictors of variance close to zero, are generally removed, assuming they are not very informative, this procedure often results in removing the strongest predictors of the model (Gelman et al., 2008) and, therefore, this practice was not followed here. However, words that have constant frequencies in all texts of the corpus have truly zero variance and have been removed. 

```{r ZVRemoving}
ZVIndex <- which(
    nearZeroVar(titlesData[, -(1:2)],
                saveMetrics = TRUE,
                names = FALSE,
                foreach = TRUE,
                allowParallel=TRUE
                )$zeroVar
    )

if (sum(ZVIndex) > 0) {
        titlesData <- titlesData[, -(ZVIndex + 2)]
}

ZVIndex <- which(nearZeroVar(synopsesData[, -(1:2)],
                             saveMetrics = TRUE,
                             names = FALSE,
                             foreach = TRUE,
                         allowParallel=TRUE)$zeroVar)

if (sum(ZVIndex) > 0) {
        synopsesData <- synopsesData[, -(ZVIndex + 2)]
}
```

Another problem arises from highly correlated variables; The usual PCA approach (Kuhn, 2008) could make it more difficult to interpret the predictors and therefore chose instead to simply remove variables with a correlation between them, as measured by the Pearson correlation coefficient, greater than 80%. 

```{r corrRemoving}
corIndex <-
    findCorrelation(cor(titlesData[, -(1:2)]),
                    cutoff = 0.8)
titlesData <- titlesData[, -(corIndex + 2)]

corIndex <-
    findCorrelation(cor(synopsesData[, -(1:2)]),
                    cutoff = 0.8)
synopsesData <- synopsesData[, -(corIndex + 2)]
```

After all of these cleaning procedures, the data set has been reduced to `r ncol(synopsesData[, -(1: 2)])` words (columns).

Gelman et al. (2008) suggests that the continuous variables should be centered on an average value of *0* and rescaled to a standard deviation of *0.5* to resemble them to binary variables, which assume only the values *0* and *1*. In this case, however, as if only interested in the presence or absence of words, instead of their frequency, the variables were rescaled as binary, that is, frequency values greater than zero were transformed to *1*.

```{r GScaling}
titlesData <-
        cbind(DocNo = titlesData$DocNo,
              GenCat = titlesData$GenCat,
              as.data.frame(ifelse(titlesData[, -(1:2)] > 0, 1, 0)))
titlesData[, -(1:2)] <-
        lapply(titlesData[, -(1:2)], function(lista)
                factor(
                        lista,
                        levels = c(0, 1),
                        labels = c('ausente', 'presente'),
                        ordered = TRUE
                ))

synopsesData <-
        cbind(DocNo = synopsesData$DocNo,
              GenCat = synopsesData$GenCat,
              as.data.frame(ifelse(synopsesData[, -(1:2)] > 0, 1, 0)))
synopsesData[, -(1:2)] <-
        lapply(synopsesData[, -(1:2)], function(lista)
                factor(
                        lista,
                        levels = c(0, 1),
                        labels = c('ausente', 'presente'),
                        ordered = TRUE
                ))
```

The usual practice of machine learning recommends randomly subdividing the data set and allocating at least 70% of them to the training of the model, reserving the remaining 30% for validation. The R language has the resources to perform this subdivision automatically, taking into account a balance between the data categories in the two subsets.

In order to ensure reproducibility, a global seed (*42*) has been established for the pseudorandom number generator.

```{r partitioning}
set.seed(42) # The Answer to the Ultimate Question of Life, the Universe, and Everything (Douglas Adams)

inTrain <-
    createDataPartition(
        y = titlesData$GenCat,
        p = 0.7,
        list = FALSE
        )

trainTitles <- titlesData[inTrain, ]
testTitles <- titlesData[-inTrain, ]

inTrain <-
        createDataPartition(
                y = synopsesData$GenCat,
                p = 0.7,
                list = FALSE
                )
trainSynopses <- synopsesData[inTrain, ]
testSynopses <- synopsesData[-inTrain, ]
```

After randomly subdividing the data set into approximately 70% of them for model training and 30% for validation, it resulted in sets of `r nrow (trainTitles)` and `r nrow (testTitles)` remarks (books) respectively , For the same `n ncol (titlesData [, - (1: 2)])` columns of the headings and `n ncol (synopsesData [, - (1: 2)]) of the synopses words in both sets.

When the data set is small relative to the number of variables, in order to avoid overfitting and to reduce forecasting errors, when applied outside the sample (*out-of-sample errors*), it is usually performed a cross-validation k-fold (*k-fold cross-validation*) (Seni; Elder, 2010, pp. 26-28) on the training data set. In this case, a 7-fold-cross-validation was performed.

```{r trControl}
set.seed(42) # The Answer to the Ultimate Question of Life, the Universe, and Everything (Douglas Adams)

trCont <-
    trainControl(method = "cv",
                 number = 7,
                 verboseIter = FALSE)
```

A number of the most popular machine learning algorithms available in the *Caret package* (Kuhn, 2008) were tested, including *Support Vector Machines with Radial Basis Function Kernel* (Karatzoglou et al., 2004) *eXtreme Gradient Boosting* (Chen; He; Benetsy, 2016; Friedman, 2001), *Random Forests* (Breiman, 2001; Liaw; Wiener, 2002), and *Recursive Partitioning and Regression Trees* (Breiman et al., 1984; Therenau; Atkinson; Ripley, 2015), among many others. 

```{r ModelSVM}
SVM_modelTit <-
    train(as.factor(GenCat) ~ .,
          data =  data.frame(trainTitles[, -1]),
          method = "svmRadial",
          trControl = trCont)

SVM_modelSyn <-
    train(as.factor(GenCat) ~ .,
          data =  data.frame(trainSynopses[, -1]),
          method = "svmRadial",
          trControl = trCont)
```

```{r ModelXGBoost}
XGBoost_modelTit <-
    train(as.factor(GenCat) ~ .,
          data =  data.frame(trainTitles[, -1]),
          method = "xgbTree",
          trControl = trCont)

XGBoost_modelSyn <-
    train(as.factor(GenCat) ~ .,
          data =  data.frame(trainSynopses[, -1]),
          method = "xgbTree",
          trControl = trCont)
```

```{r ModelRForest}
RForest_modelTit <-
    train(as.factor(GenCat) ~ .,
          data =  data.frame(trainTitles[, -1]),
          method = "rf",
          trControl = trCont)

RForest_modelSyn <-
    train(as.factor(GenCat) ~ .,
          data =  data.frame(trainSynopses[, -1]),
          method = "rf",
          trControl = trCont)
```

```{r ModelRpart}
Rpart_modelTit <-
        train(as.factor(GenCat) ~ .,
              data = data.frame(trainTitles[, -1]),
              method = "rpart",
              trControl = trCont,
              control = rpart.control(minsplit = 3,
                                      maxdepth = 22)
        )

Rpart_modelSyn <- 
    train(as.factor(GenCat) ~ .,
          data = data.frame(trainSynopses[, -1]),
          method = "rpart",
          trControl = trCont,
          control=rpart.control(minsplit = 3, 
                                maxdepth = 22))
```

After applying each model to the training datasets, the Caret package also automatically calculates the usual Jordan accuracy and Cohen Kappa index parameters to evaluate the expectations of the models' ability to classify the test data. The results of these parameters for titles and synopses are presented in Tables 2 and 3.

```{r comparison}
ModelNames <-
    list("SVM", "XGBoost", "RForest", "RPART")

ModelsTit <-
    list(SVM_modelTit,
         XGBoost_modelTit,
         RForest_modelTit,
         Rpart_modelTit)

PerformancesF <- function(model) {
        ConfMatrix <- confusionMatrix(
                model,
                norm = "none",
                dnn = c("Classe predita", "Classe real"),
                positive = 'pseudociência'
        )$table
        Accuracy <- round(sum(diag(ConfMatrix)) / sum(ConfMatrix)
                          ,
                          3)
        Kappa <- round(cohen.kappa(ConfMatrix)$kappa
                       ,
                       3)
        c(Accuracy, Kappa)
}
Performances <- lapply(ModelsTit, PerformancesF)

class.errorF <- function(model) {
        ConfMatrix <-
                as.matrix(table(predict(model),
                                trainTitles$GenCat))
        round(max(c(
                ConfMatrix[1, 2] /
                        ConfMatrix[1, 1],
                ConfMatrix[2, 1] /
                        ConfMatrix[2, 2]
        )), 3)
}
#class.error <- sapply(ModelsTit, class.errorF)

comparisonTit <-
    cbind(ModelNames, 
          Performances)

kable(comparisonTit,
      digits = 3,
      align = c('l', 'r', 'r', 'r'),
      caption = "Comparação entre modelos para títulos")

ModelsSyn <-
    list(SVM_modelSyn,
         XGBoost_modelSyn,
         RForest_modelSyn,
         Rpart_modelSyn)

AccuracyF <- function(model) {
    x <- model %>%
        getElement('results') %>%
        getElement('Accuracy')
    round(max(x), 3)
}
Accuracy <- sapply(ModelsSyn, AccuracyF)

KappF <- function(model) {
    x <- model %>%
        getElement('results') %>%
        getElement('Kappa')
    round(max(x), 3)
}
Kappa <- sapply(ModelsSyn, KappF)

class.errorF <- function(model) {
        ConfMatrix <-
                as.matrix(table(predict(model),
                                trainSynopses$GenCat))
        round(max(c(
                ConfMatrix[1, 2] /
                        ConfMatrix[1, 1],
                ConfMatrix[2, 1] /
                        ConfMatrix[2, 2]
        )), 3)
}
#class.error <- sapply(ModelsSyn, class.errorF)

comparisonSyn <-
    cbind(ModelNames, 
          Accuracy, 
          Kappa)

kable(comparisonSyn,
      digits = 3,
      align = c('l', 'r', 'r', 'r'),
      caption = "Comparação entre modelos para sinopses")
```

From these tables, notes that the SVMRadial model is the one that looks most promising, with the RPART second, in the set titles and synopses.

Now models must be validated by applying them to the test data sets, both title words and synopses, with `r nrow (testTitles)` books each, simulating the actual case of a visitor choosing books in the Bookstores for their titles and synopses. The results can be seen in the confusion matrices of Tables 4, 5, 6, and 7.

```{r ConfMatrix}
ConfMatrixTitSVM <-
    as.matrix(table(testTitles$GenCat,
                    predict(SVM_modelTit, testTitles[, -1])
                    )
              )

ConfMatrixTitSVM <- ConfMatrixTitSVM[
    order(row.names(ConfMatrixTitSVM), decreasing = TRUE),
    order(colnames(ConfMatrixTitSVM), decreasing = TRUE)]

ConfMatrixTitSVM <- cbind(ConfMatrixTitSVM, 
                   class.error = c(ConfMatrixTitSVM[1,2] /
                                           ConfMatrixTitSVM[1,1],
                                   ConfMatrixTitSVM[2,1] /
                                           ConfMatrixTitSVM[2,2]
                                   )
                   )

kable(ConfMatrixTitSVM, 
      digits = 3,
      caption = "Matriz de confusão do modelo SVMRadial para títulos")

ConfMatrixSynSVM <-
    as.matrix(table(testSynopses$GenCat,
                    predict(SVM_modelSyn, testSynopses[, -1])
                    )
              )

ConfMatrixSynSVM <- ConfMatrixSynSVM[
    order(row.names(ConfMatrixSynSVM), decreasing = TRUE),
    order(colnames(ConfMatrixSynSVM), decreasing = TRUE)]

ConfMatrixSynSVM <- cbind(ConfMatrixSynSVM, 
                   class.error = c(ConfMatrixSynSVM[1,2] /
                                           ConfMatrixSynSVM[1,1],
                                   ConfMatrixSynSVM[2,1] /
                                           ConfMatrixSynSVM[2,2]
                                   )
                   )

kable(ConfMatrixSynSVM, 
      digits = 3,
      caption = "Matriz de confusão do modelo SVMRadial para sinopses")

ConfMatrixTitRpart <-
    as.matrix(table(testTitles$GenCat,
                    predict(Rpart_modelTit, testTitles[, -1])
                    )
              )

ConfMatrixTitRpart <- ConfMatrixTitRpart[
    order(row.names(ConfMatrixTitRpart), decreasing = TRUE),
    order(colnames(ConfMatrixTitRpart), decreasing = TRUE)]

ConfMatrixTitRpart <- cbind(ConfMatrixTitRpart, 
                   class.error = c(ConfMatrixTitRpart[1,2] /
                                           ConfMatrixTitRpart[1,1],
                                   ConfMatrixTitRpart[2,1] /
                                           ConfMatrixTitRpart[2,2]
                                   )
                   )

kable(ConfMatrixTitRpart, 
      digits = 3,
      caption = "Matriz de confusão do modelo RPART para títulos")

ConfMatrixSynRpart <-
    as.matrix(table(testSynopses$GenCat,
                    predict(Rpart_modelSyn, testSynopses[, -1])
                    )
              )

ConfMatrixSynRpart <- ConfMatrixSynRpart[
    order(row.names(ConfMatrixSynRpart), decreasing = TRUE),
    order(colnames(ConfMatrixSynRpart), decreasing = TRUE)]

ConfMatrixSynRpart <- cbind(ConfMatrixSynRpart, 
                   class.error = c(ConfMatrixSynRpart[1,2] /
                                           ConfMatrixSynRpart[1,1],
                                   ConfMatrixSynRpart[2,1] /
                                           ConfMatrixSynRpart[2,2]
                                   )
                   )

kable(ConfMatrixSynRpart, 
      digits = 3,
      caption = "Matriz de confusão do modelo RPART para sinopses")
``` 

As can be seen from the tables, all `r testTitles[testTitles$GenCat == "ciência",])` test set scientific books were correctly classified in the 'science' category, but not all pseudoscientific books were recognized as By their titles. The RPART model was the one that had the lowest classification error rate (`r round(ConfMatrixTit[1,2]/ConfMatrixTit[1,1], 2)*100`%), by title words. 

The `r length(which(predict(Rpart_modelTit, testTitles[, -1]) != testTitles$GenCat))` books that were incorrectly classified by their titles are::
`r booksData$Titulo[booksData$N %in% testTitles$DocNo[which(predict(Rpart_modelTit, testTitles[, -1]) != testTitles$GenCat)]]`

```{r finalModel}
markersTit <-
        as.character(
                unique(Rpart_modelTit$finalModel$frame$var[
                        Rpart_modelTit$finalModel$frame$var != "<leaf>"
                        ]
                       )
                )

markersSyn <-
        as.character(
                unique(Rpart_modelSyn$finalModel$frame$var[
                        Rpart_modelSyn$finalModel$frame$var != "<leaf>"
                        ]
                       )
                )
```

The model is an economic one, since it consists of a regression tree with only `r length (markersTit)` 'sheets' (Figure 4a), related to the following `r length (markersTit)` title words: `r markersTit`.

This model discriminates with reasonable success among categories, so that the presence of any of those words in a book synopsis indicates that it belongs to the category "quantum mysticism" and not to "science", as seen from the confusion matrix of Table 2 for the titles and that of Table 3 for the synopses.

```{r RpartPlot}
fancyRpartPlot(Rpart_modelTit$finalModel, sub = "")
fancyRpartPlot(Rpart_modelSyn$finalModel, sub = "")
```

```{r RpartPlot}
Rpart_modelTitR <- 
    train(as.factor(GenCat) ~ .,
          data = data.frame(trainTitles[, -1]),
          method = "rpart",
          trControl = trCont,
          control=rpart.control(minsplit = 3, 
                                maxdepth = 5))
fancyRpartPlot(Rpart_modelTitR$finalModel, sub = "", cex = 1.5)
```


```{r}
teste <- trainTitles
for (i in 3:ncol(trainTitles))
        teste[,i] <- as.logical(trainTitles[,i])
Rpart_modelTest <- 
    train(Category ~ .,
          data = data.frame(teste[, -1]),
          method = "rpart",
          trControl = trCont,
          control=rpart.control(minsplit = 3, 
                                maxdepth = 5))
fancyRpartPlot(Rpart_modelTest$finalModel, sub = "", type = 4)
```

```{r}
CairoPNG(
        filename = paste0("image/", "tree.png"),
        width = 3600,
        height = 3600,
        dpi = 600,
        bg = "white"
)
rpart.plot(Rpart_modelTitR$finalModel, sub = "", under = FALSE, lt = " ", eq = "", ge = "", split.prefix = "", split.suffix = "", yesno = 2, 3, yes.text = 'ausente', fallen.leaves=TRUE, no.text ='presente', type = 2, extra = 100, box.palette = c("dodgerblue", "brown1"))
dev.off()
```


# References
- Breiman, Leo et al. *Classification and Regression Trees*. London: Chapman and Hall/CRC, 1984.
- Breiman, Leo. Random Forests. *Machine Learning*, v. 45, n. 1, p. 5-32, 2001.
- Friedman, Jerome H. Greedy Function Approximation: A Gradient Boosting Machine. *The Annals of Statistics*, v. 29, n. 5, p. 1189-1232, out. 2001.
- Gelman, Andrew et al. A weakly informative default prior distribution for logistic and other regression models. *The Annals of Applied Statistics*, v. 2, n. 4, p. 1360-1383, dez. 2008.
- Hastie, Trevor J.; Pregibon, Daryl. Generalized linear models. In: Chambers, John M.; Hastie, Trevor J. (Org.). . *Statistical Models in S*. Boca Raton, FL: CRC Press, 1991. 
- Kuhn, Max. Building Predictive Models in R Using the caret Package. *Journal of Statistical Software*, v. 28, n. 5, nov. 2008.
- R Core Team. *R: A language and environment for statistical computing*. Vienna: R Foundation for Statistical Computing, 2016. Available at R site: https://www.R-project.org/. 
- Seni, Giovanni; Elder, John F. *Ensemble Methods in Data Mining*: Improving Accuracy Through Combining Predictions. San Rafael, CA: Morgan & Claypool, 2010.
- Suykens, J.A.K.; Vandewalle, J.; De Moor, B. Optimal control by least squares support vector machines. *Neural Networks*, v. 14, n. 1, p. 23-35, jan. 2001.
